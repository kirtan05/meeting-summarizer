{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f60c7b-6631-4390-af06-01d1229424a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93618867-dc61-46d4-801c-425d13ead04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 09:01:02.482260: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-17 09:01:02.516649: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-17 09:01:02.516691: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-17 09:01:02.516732: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 09:01:02.526011: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-17 09:01:03.510487: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, Form, BackgroundTasks, HTTPException\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os, uuid\n",
    "from pathlib import Path\n",
    "import aiofiles\n",
    "import smtplib\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from huggingface_hub import login\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import torch\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allows all origins\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Replace this with your Hugging Face token\n",
    "hf_token = os.getenv(\"HF_API\")\n",
    "\n",
    "# Log in\n",
    "login(token=hf_token)\n",
    "\n",
    "adapter_model_id = \"SleepyGorilla/gemma-meetingbank-it\"\n",
    "base_model_id = \"google/gemma-3-1b-it\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "\n",
    "# Load base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load PEFT adapter and apply it\n",
    "model = PeftModel.from_pretrained(base_model, adapter_model_id)\n",
    "print(\"Model Loaded\")\n",
    "system_message = \"\"\"You are an expert meeting assistant. Given the transcript of a meeting, your task is to read and analyze it, then generate a structured summary that captures the essence of the discussion.\n",
    "\n",
    "Your summary must be correct, clear, thorough, and categorized into the following sections:\n",
    "\n",
    "Discussion Points/Agenda : A brief overview of the main topics discussed during the meeting.\n",
    "\n",
    "Decisions Made: Any clear conclusions, approvals, or agreed-upon actions.\n",
    "\n",
    "Action Items: A list of tasks assigned to individuals or teams, with deadlines if mentioned.\n",
    "\"\"\"\n",
    "\n",
    "def generate_summary(transcript_text: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": transcript_text}\n",
    "    ]\n",
    "\n",
    "    encoded = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        return_tensors=\"pt\",\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    input_ids = encoded.to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_new_tokens=2048,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True\n",
    "        )\n",
    "\n",
    "    generated_tokens = output[0][input_ids.shape[-1]:]\n",
    "    summary = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Hello from FastAPI\"}\n",
    "\n",
    "AZURE_SPEECH_KEY = os.getenv(\"AZURE_SPEECH_KEY\")\n",
    "AZURE_SPEECH_REGION = \"centralindia\"\n",
    "EMAIL_SENDER = \"your@email.com\"\n",
    "EMAIL_PASSWORD = \"your_email_password\"\n",
    "subscription_key = os.getenv(\"AZURE_TRANSLATE_KEY\")\n",
    "\n",
    "def detect_language(text, subscription_key):\n",
    "    endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
    "    path = \"/detect?api-version=3.0\"\n",
    "    url = endpoint + path\n",
    "    print(subscription_key)\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "        \"Ocp-Apim-Subscription-Region\": \"centralindia\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    body = [{\"text\": text}]\n",
    "    response = requests.post(url, headers=headers, json=body)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        detected_lang = response.json()[0]['language']\n",
    "        return detected_lang\n",
    "    else:\n",
    "        print(\"Language detection failed\")\n",
    "        return None\n",
    "\n",
    "def translate(text, subscription_key):\n",
    "    detected_lang = detect_language(text, subscription_key)\n",
    "\n",
    "    if detected_lang == \"en\":\n",
    "        print(\"Text is already in English. Skipping translation.\")\n",
    "        return text\n",
    "\n",
    "    endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
    "    path = \"/translate\"\n",
    "    url = endpoint + path\n",
    "\n",
    "    params = {\n",
    "        \"api-version\": \"3.0\",\n",
    "        \"from\": detected_lang,\n",
    "        \"to\": \"en\"\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "        \"Ocp-Apim-Subscription-Region\": \"centralindia\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    body = [{\"text\": text}]\n",
    "    response = requests.post(url, params=params, headers=headers, json=body)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        translations = response.json()\n",
    "        translated_text = translations[0][\"translations\"][0][\"text\"]\n",
    "        print(f\"Translated from {detected_lang} to English: {translated_text}\")\n",
    "        return translated_text\n",
    "    else:\n",
    "        print(\"Translation failed\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio(file_path: str) -> str:\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=file_path)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        return result.text\n",
    "    else:\n",
    "        raise HTTPException(status_code=500, detail=\"Speech recognition failed.\")\n",
    "\n",
    "\n",
    "@app.post(\"/upload/audio\")\n",
    "async def upload_audio(background_tasks: BackgroundTasks, file: UploadFile = File(...), email: str = Form(...)):\n",
    "    temp_path = f\"temp/{uuid.uuid4()}_{file.filename}\"\n",
    "    os.makedirs(\"temp\", exist_ok=True)\n",
    "\n",
    "    async with aiofiles.open(temp_path, \"wb\") as out_file:\n",
    "        content = await file.read()\n",
    "        await out_file.write(content)\n",
    "\n",
    "    try:\n",
    "        transcribed_text = transcribe_audio(temp_path)\n",
    "        transcribed_text = translate(transcribed_text, subscription_key)\n",
    "        if transcribed_text is None:\n",
    "            raise HTTPException(status_code=500, detail=\"Translation failed.\")\n",
    "        result = generate_summary(transcribed_text)\n",
    "       \n",
    "        output_str = f\"Transcription: {transcribed_text}\\nModel Output: {result}\"\n",
    "\n",
    "        # background_tasks.add_task(send_email, email, output_str)\n",
    "        return {\"message\": output_str}\n",
    "    finally:\n",
    "        os.remove(temp_path)\n",
    "\n",
    "\n",
    "@app.post(\"/upload/text\")\n",
    "async def upload_text(background_tasks: BackgroundTasks, file: UploadFile = File(...), email: str = Form(...)):\n",
    "    content = await file.read()\n",
    "    text = content.decode(\"utf-8\")\n",
    "    text = translate(text, subscription_key)\n",
    "    if text is None:\n",
    "        raise HTTPException(status_code=500, detail=\"Translation failed.\")\n",
    "    result = generate_summary(text)\n",
    "    output_str = f\"Model Output: {result}\"\n",
    "\n",
    "    # background_tasks.add_task(send_email, email, output_str)\n",
    "    return {\"message\": output_str}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae7c7f2-f6c7-4b62-b75a-4afa9e3df252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: https://d6e8-184-105-162-170.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "# Open a tunnel on the port where Uvicorn will run\n",
    "ngrok.set_auth_token(\"2vql2MRAvxhvDYjLTZvJc7rf8df_6G4SwFuko5GuU1bG3xMZv\")\n",
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "\n",
    "# Print the public URL\n",
    "print(\"Public URL:\", ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095b6db-1ae6-4d2b-b443-9b271cd757b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [2113]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     27.97.221.8:0 - \"GET /upload/text HTTP/1.1\" 405 Method Not Allowed\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import uvicorn\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Launch the server inside notebook\n",
    "uvicorn.run(app, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4acc42-9be2-48ed-ab61-29fa02b16330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
