{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f60c7b-6631-4390-af06-01d1229424a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93618867-dc61-46d4-801c-425d13ead04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-7' coro=<Server.serve() done, defined at /home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/uvicorn/main.py\", line 580, in run\n",
      "    server.run()\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/uvicorn/server.py\", line 66, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 350, in __wakeup\n",
      "    self.__step()\n",
      "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/uvicorn/server.py\", line 69, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/uvicorn/server.py\", line 330, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-17' coro=<Server.serve() done, defined at /home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/uvicorn/main.py\", line 580, in run\n",
      "    server.run()\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/uvicorn/server.py\", line 66, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 350, in __wakeup\n",
      "    self.__step()\n",
      "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/uvicorn/server.py\", line 69, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/martin/data/meeting-summarizer/martin/lib/python3.11/site-packages/uvicorn/server.py\", line 330, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, Form, BackgroundTasks, HTTPException\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os, uuid\n",
    "from pathlib import Path\n",
    "import aiofiles\n",
    "import smtplib\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from peft import PeftModel\n",
    "# from huggingface_hub import login\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "# import torch\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allows all origins\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Replace this with your Hugging Face token\n",
    "# hf_token = \"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\"\n",
    "\n",
    "# # Log in\n",
    "# login(token=hf_token)\n",
    "\n",
    "# adapter_model_id = \"SleepyGorilla/gemma-meetingbank-it\"\n",
    "# base_model_id = \"google/gemma-3-1b-it\"\n",
    "\n",
    "# # Load tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "\n",
    "# # Load base model\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     base_model_id,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "# # Load PEFT adapter and apply it\n",
    "# model = PeftModel.from_pretrained(base_model, adapter_model_id)\n",
    "print(\"Model Loaded\")\n",
    "system_message = \"\"\"You are an expert meeting assistant. Given the transcript of a meeting, your task is to read and analyze it, then generate a structured summary that captures the essence of the discussion.\n",
    "\n",
    "Your summary must be correct, clear, thorough, and categorized into the following sections:\n",
    "\n",
    "Discussion Points/Agenda : A brief overview of the main topics discussed during the meeting.\n",
    "\n",
    "Decisions Made: Any clear conclusions, approvals, or agreed-upon actions.\n",
    "\n",
    "Action Items: A list of tasks assigned to individuals or teams, with deadlines if mentioned.\n",
    "\"\"\"\n",
    "\n",
    "# def generate_summary(transcript_text: str) -> str:\n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": system_message},\n",
    "#         {\"role\": \"user\", \"content\": transcript_text}\n",
    "#     ]\n",
    "\n",
    "#     encoded = tokenizer.apply_chat_template(\n",
    "#         messages,\n",
    "#         return_tensors=\"pt\",\n",
    "#         add_generation_prompt=True\n",
    "#     )\n",
    "\n",
    "#     input_ids = encoded.to(model.device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output = model.generate(\n",
    "#             input_ids=input_ids,\n",
    "#             max_new_tokens=2048,\n",
    "#             temperature=0.7,\n",
    "#             top_p=0.9,\n",
    "#             do_sample=True\n",
    "#         )\n",
    "\n",
    "#     generated_tokens = output[0][input_ids.shape[-1]:]\n",
    "#     summary = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "#     return summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def detect_language(text, subscription_key):\n",
    "    endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
    "    path = \"/detect?api-version=3.0\"\n",
    "    url = endpoint + path\n",
    "    print(subscription_key)\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "        \"Ocp-Apim-Subscription-Region\": \"centralindia\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    body = [{\"text\": text}]\n",
    "    response = requests.post(url, headers=headers, json=body)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        detected_lang = response.json()[0]['language']\n",
    "        return detected_lang\n",
    "    else:\n",
    "        print(\"Language detection failed\")\n",
    "        return None\n",
    "\n",
    "def translate(text, subscription_key):\n",
    "    detected_lang = detect_language(text, subscription_key)\n",
    "\n",
    "    if detected_lang == \"en\":\n",
    "        print(\"Text is already in English. Skipping translation.\")\n",
    "        return text\n",
    "\n",
    "    endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
    "    path = \"/translate\"\n",
    "    url = endpoint + path\n",
    "\n",
    "    params = {\n",
    "        \"api-version\": \"3.0\",\n",
    "        \"from\": detected_lang,\n",
    "        \"to\": \"en\"\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "        \"Ocp-Apim-Subscription-Region\": \"centralindia\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    body = [{\"text\": text}]\n",
    "    response = requests.post(url, params=params, headers=headers, json=body)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        translations = response.json()\n",
    "        translated_text = translations[0][\"translations\"][0][\"text\"]\n",
    "        print(f\"Translated from {detected_lang} to English: {translated_text}\")\n",
    "        return translated_text\n",
    "    else:\n",
    "        print(\"Translation failed\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Hello from FastAPI\"}\n",
    "\n",
    "AZURE_SPEECH_KEY = os.getenv(\"AZURE_SPEECH_KEY\")\n",
    "AZURE_SPEECH_REGION = \"centralindia\"\n",
    "EMAIL_SENDER = \"your@email.com\"\n",
    "EMAIL_PASSWORD = \"your_email_password\"\n",
    "subscription_key = os.getenv(\"AZURE_TRANSLATE_KEY\")\n",
    "\n",
    "\n",
    "def transcribe_audio(file_path: str) -> str:\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=file_path)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        return result.text\n",
    "    else:\n",
    "        raise HTTPException(status_code=500, detail=\"Speech recognition failed.\")\n",
    "\n",
    "\n",
    "@app.post(\"/upload/audio\")\n",
    "async def upload_audio(background_tasks: BackgroundTasks, file: UploadFile = File(...), email: str = Form(...)):\n",
    "    temp_path = f\"temp/{uuid.uuid4()}_{file.filename}\"\n",
    "    os.makedirs(\"temp\", exist_ok=True)\n",
    "\n",
    "    async with aiofiles.open(temp_path, \"wb\") as out_file:\n",
    "        content = await file.read()\n",
    "        await out_file.write(content)\n",
    "\n",
    "    try:\n",
    "        transcribed_text = transcribe_audio(temp_path)\n",
    "        transcribed_text = translate(transcribed_text, subscription_key)\n",
    "        if not transcribed_text:\n",
    "            raise HTTPException(status_code=500, detail=\"Translation failed.\")\n",
    "        # result = generate_summary(transcribed_text)\n",
    "        print(transcribed_text)\n",
    "        result = \"fs\"\n",
    "        output_str = f\"Transcription: {transcribed_text}\\nModel Output: {result}\"\n",
    "\n",
    "        # background_tasks.add_task(send_email, email, output_str)\n",
    "        return {\"message\": \"Processed and email sent.\"}\n",
    "    finally:\n",
    "        os.remove(temp_path)\n",
    "\n",
    "\n",
    "@app.post(\"/upload/text\")\n",
    "async def upload_text(background_tasks: BackgroundTasks, file: UploadFile = File(...), email: str = Form(...)):\n",
    "    content = await file.read()\n",
    "    text = content.decode(\"utf-8\")\n",
    "    text = translate(text, subscription_key)\n",
    "    if not text:\n",
    "        raise HTTPException(status_code=500, detail=\"Translation failed.\")\n",
    "    # result = generate_summary(text)\n",
    "    result = \"fs\"\n",
    "    output_str = f\"Model Output: {result}\"\n",
    "\n",
    "    # background_tasks.add_task(send_email, email, output_str)\n",
    "    return {\"message\": output_str}\n",
    "    return {\"message\": \"Processed and email sent.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ae7c7f2-f6c7-4b62-b75a-4afa9e3df252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: https://bf38-2402-a00-172-8f42-be24-11ff-fe2e-503b.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "ngrok_key = os.getenv(\"NGROK_KEY\")\n",
    "# Open a tunnel on the port where Uvicorn will run\n",
    "ngrok.set_auth_token(ngrok_key)\n",
    "ngrok_tunnel = ngrok.connect(8006)\n",
    "\n",
    "# Print the public URL\n",
    "print(\"Public URL:\", ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3095b6db-1ae6-4d2b-b443-9b271cd757b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [39951]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8006 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6y9aHbd70ihSwTRVXfEJXnrrmSMvZrGt4DRYmVUAGEGSElMlLdgLJQQJ99AKACGhslBXJ3w3AAAbACOGrZgR\n",
      "Text is already in English. Skipping translation.\n",
      "What are the legal consequences of hacking under Indian cyber law?\n",
      "INFO:     103.84.198.236:0 - \"POST /upload/audio HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [39951]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import uvicorn\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Launch the server inside notebook\n",
    "uvicorn.run(app,host=\"0.0.0.0\", port=8006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4acc42-9be2-48ed-ab61-29fa02b16330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "martin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
