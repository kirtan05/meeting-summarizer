# ğŸ§  Meeting Summarizer (NLP Project)

A full-stack NLP project for generating high-quality meeting summaries using transformer models. It includes dataset preparation, model fine-tuning, backend deployment, and a frontend interface. The entire stack leverages Groq + LLaMA for inference and Gemma for fine-tuning.

---

## ğŸ¥ Demo

You can check it out in a [Video Demo](https://youtu.be/N85zmYQjBEA)!

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ backend/                      # Backend notebook and server
â”‚   â””â”€â”€ backend.ipynb
â”œâ”€â”€ frontend/                     # React-based user interface
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ App.jsx               # Set NGROK URL here
â”œâ”€â”€ model/                        # Fine-tuning and model-related scripts
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ train.ipynb
â”œâ”€â”€ dataset/                      # Dataset generation and raw data
â”‚   â”œâ”€â”€ dataset_generation.ipynb
â”‚   â””â”€â”€ meetingbank_final_llama4.csv
â”œâ”€â”€ tests/                        # Test files and samples
â”‚   â””â”€â”€ test_audio.wav
â”œâ”€â”€ assets/                       # Images and visuals
â”‚   â””â”€â”€ architecture.png
â”œâ”€â”€ .env.example                  # Template for required environment variables
â””â”€â”€ README.md
```

---

## ğŸš€ Quickstart

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/meeting-summarizer.git
cd meeting-summarizer
```

---

### 2. Generate Dataset

Navigate to `dataset/dataset_generation.ipynb`:

- Loads MeetingBank dataset:
  ```python
  from datasets import load_dataset
  dataset = load_dataset("huuuyeah/meetingbank")
  ```

- Inference using Groq API (`llama-4-scout`)
- Output: `meetingbank_final_llama4.csv`

---

### 3. Fine-tune the Model

In the `model/` folder:

- Install dependencies:

```bash
pip install -r requirements.txt
```

- Open `train.ipynb` and fine-tune the model using:

```python
model_id = "google/gemma-3-1b-it"
# Alternatives: "google/gemma-3-4b-pt", "gemma-3-12b-pt", "gemma-3-27b-pt"
```

---

### 4. Run Backend

Navigate to `backend/backend.ipynb` and run all cells:

```python
from pyngrok import ngrok
import os

NGROK_KEY = os.getenv("NGROK_KEY")
ngrok.set_auth_token(NGROK_KEY)
tunnel = ngrok.connect(8000)
print("Public URL:", tunnel.public_url)
```

> Copy the printed public URL â€” this is your backend endpoint.

---

### 5. Start Frontend

In the `frontend/` folder:

- Set the backend URL in `src/App.jsx`:

```js
const API_BASE_URL = 'https://xxxx-xx-xx-xxx.ngrok-free.app';
```

- Run frontend:

```bash
npm install
npm run dev
```

---

## ğŸ” Environment Variables

Create a `.env` file using `.env.example` and add:

```env
GROQ_API=
HF_API=
AZURE_SPEECH_KEY=
AZURE_TRANSLATE_KEY=
NGROK_KEY=
gmail_user=
gmail_password=   # App password only
```

---

## ğŸ“¸ Architecture

![architecture](assets/architecture.png)

---

## âœ… Final Notes

- Uses [MeetingBank](https://huggingface.co/datasets/huuuyeah/meetingbank) dataset
- Groq LLaMA-4 used for inference during dataset generation
- Fine-tunes Googleâ€™s Gemma models with HuggingFace
- React frontend powered by Vite
- Backend served using `pyngrok` tunnel

---

**Made with ğŸ¤ by Kirtan, Martin and Siddhant**

```
