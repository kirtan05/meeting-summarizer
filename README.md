# üß† Meeting Summarizer (NLP Project)

A full-stack NLP project for generating high-quality meeting summaries using transformer models. It includes dataset preparation, model fine-tuning, backend deployment, and a frontend interface. The entire stack leverages Groq + LLaMA for inference and Gemma for fine-tuning.

---

## üé• Demo

You can check it out in a [Video Demo](https://youtu.be/N85zmYQjBEA)!

---

## üìÅ Project Structure

```
.
‚îú‚îÄ‚îÄ backend/                      # Backend notebook and server
‚îÇ   ‚îî‚îÄ‚îÄ backend.ipynb
‚îú‚îÄ‚îÄ frontend/                     # React-based user interface
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.jsx               # Set NGROK URL here
‚îú‚îÄ‚îÄ model/                        # Fine-tuning and model-related scripts
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ train.ipynb
‚îú‚îÄ‚îÄ dataset/                      # Dataset generation and raw data
‚îÇ   ‚îú‚îÄ‚îÄ dataset_generation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ meetingbank_final_llama4.csv
‚îú‚îÄ‚îÄ tests/                        # Test files and samples
‚îÇ   ‚îî‚îÄ‚îÄ test_audio.wav
‚îú‚îÄ‚îÄ assets/                       # Images and visuals
‚îÇ   ‚îî‚îÄ‚îÄ architecture.png
‚îú‚îÄ‚îÄ .env.example                  # Template for required environment variables
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Quickstart

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/meeting-summarizer.git
cd meeting-summarizer
```

---

### 2. Generate Dataset

Navigate to `dataset/dataset_generation.ipynb`:

- Loads MeetingBank dataset:
  ```python
  from datasets import load_dataset
  dataset = load_dataset("huuuyeah/meetingbank")
  ```

- Inference using Groq API (`llama-4-scout`)
- Output: `meetingbank_final_llama4.csv`

---

### 3. Fine-tune the Model

In the `model/` folder:

- Install dependencies:

```bash
pip install -r requirements.txt
```

- Open `train.ipynb` and fine-tune the model using:

```python
model_id = "google/gemma-3-1b-it"
# Alternatives: "google/gemma-3-4b-pt", "gemma-3-12b-pt", "gemma-3-27b-pt"
```

---

### 4. Run Backend

Navigate to `backend/backend.ipynb` and run all cells:

```python
from pyngrok import ngrok
import os

NGROK_KEY = os.getenv("NGROK_KEY")
ngrok.set_auth_token(NGROK_KEY)
tunnel = ngrok.connect(8000)
print("Public URL:", tunnel.public_url)
```

> Copy the printed public URL ‚Äî this is your backend endpoint.

---

### 5. Start Frontend

In the `frontend/` folder:

- Set the backend URL in `src/App.jsx`:

```js
const API_BASE_URL = 'https://xxxx-xx-xx-xxx.ngrok-free.app';
```

- Run frontend:

```bash
npm install
npm run dev
```

---

## üîê Environment Variables

Create a `.env` file using `.env.example` and add:

```env
GROQ_API=
HF_API=
AZURE_SPEECH_KEY=
AZURE_TRANSLATE_KEY=
NGROK_KEY=
gmail_user=
gmail_password=   # App password only
```

---

## üìä Evaluation Metrics

| Metric           | Score   | Description                                                                 |
|------------------|---------|-----------------------------------------------------------------------------|
| **ROUGE-1**      | 0.566   | Good unigram overlap (key words).                                           |
| **ROUGE-2**      | 0.345   | Strong bigram/phrase-level fluency.                                         |
| **ROUGE-Lsum**   | 0.546   | Captures logical sentence structure and summary coherence.                  |
| **BLEU**         | 0.297   | Good n-gram overlap; reflects reference style and vocabulary.               |
| 1‚Äì4 Gram Prec.   | 0.52 / 0.33 / 0.24 / 0.19 | Expected gradual drop; longer n-grams are harder to match.      |
| **METEOR**       | 0.483   | Balances precision & recall, accounts for synonyms/stemming.               |
| **BERTScore F1** | 0.899   | Indicates excellent semantic similarity between prediction and reference.   |

---

## üìΩÔ∏è Presentation

Want to understand our methodology better? Check out our [Project Presentation](https://drive.google.com/file/d/1N0G7QRdVekMjk43ePiktin5FW4ik_sw4/view?usp=sharing).

---
## üì∏ Architecture

![architecture](assets/architecture.png)

---

## ‚úÖ Final Notes

- Uses [MeetingBank](https://huggingface.co/datasets/huuuyeah/meetingbank) dataset
- Groq LLaMA-4 used for inference during dataset generation
- Fine-tunes Google‚Äôs Gemma models with HuggingFace
- React frontend powered by Vite
- Backend served using `pyngrok` tunnel

---

**Made with ü§ç by Kirtan, Martin and Siddhant**

```
